{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hheidy0463/fma/blob/main/songrecknn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQuyB497WeXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd1ead9-cd39-4abd-def5-115027fe78e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 7323M  100 7323M    0     0  20.6M      0  0:05:54  0:05:54 --:--:-- 21.4M\n",
            "Archive:  fma_small.zip\n",
            "replace fma_small/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!curl -O https://os.unil.cloud.switch.ch/fma/fma_small.zip\n",
        "!unzip fma_small.zip\n",
        "!rm fma_small.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HAtbrWTfb3sA",
        "outputId": "9cc78f18-e7ff-44f3-935a-aeae22705e05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8kg9HA2b76a",
        "outputId": "9e4cd666-ea4e-43f0-fc3b-d9e5df8fef2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mfma_metadata\u001b[0m/  \u001b[01;34mfma_small\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGWDRKSpbagu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['AUDIO_DIR'] = '/content/fma_small'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh-qs62qcYr2",
        "outputId": "d571cd8d-d465-49a3-86c0-f052ab7bed1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory content: ['050', '034', '117', '112', '145', '073', '046', '030', '070', '054']\n"
          ]
        }
      ],
      "source": [
        "# ensure some files are accessible\n",
        "\n",
        "audio_dir = os.getenv('AUDIO_DIR')\n",
        "print(\"Directory content:\", os.listdir(audio_dir)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AeCkj2ddCpO",
        "outputId": "7def6b7b-c248-4372-f16c-b794b1dbe8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m000\u001b[0m/  \u001b[01;34m011\u001b[0m/  \u001b[01;34m022\u001b[0m/  \u001b[01;34m033\u001b[0m/  \u001b[01;34m044\u001b[0m/  \u001b[01;34m055\u001b[0m/  \u001b[01;34m066\u001b[0m/  \u001b[01;34m077\u001b[0m/  \u001b[01;34m088\u001b[0m/  \u001b[01;34m099\u001b[0m/  \u001b[01;34m110\u001b[0m/  \u001b[01;34m121\u001b[0m/  \u001b[01;34m132\u001b[0m/  \u001b[01;34m143\u001b[0m/  \u001b[01;34m154\u001b[0m/\n",
            "\u001b[01;34m001\u001b[0m/  \u001b[01;34m012\u001b[0m/  \u001b[01;34m023\u001b[0m/  \u001b[01;34m034\u001b[0m/  \u001b[01;34m045\u001b[0m/  \u001b[01;34m056\u001b[0m/  \u001b[01;34m067\u001b[0m/  \u001b[01;34m078\u001b[0m/  \u001b[01;34m089\u001b[0m/  \u001b[01;34m100\u001b[0m/  \u001b[01;34m111\u001b[0m/  \u001b[01;34m122\u001b[0m/  \u001b[01;34m133\u001b[0m/  \u001b[01;34m144\u001b[0m/  \u001b[01;34m155\u001b[0m/\n",
            "\u001b[01;34m002\u001b[0m/  \u001b[01;34m013\u001b[0m/  \u001b[01;34m024\u001b[0m/  \u001b[01;34m035\u001b[0m/  \u001b[01;34m046\u001b[0m/  \u001b[01;34m057\u001b[0m/  \u001b[01;34m068\u001b[0m/  \u001b[01;34m079\u001b[0m/  \u001b[01;34m090\u001b[0m/  \u001b[01;34m101\u001b[0m/  \u001b[01;34m112\u001b[0m/  \u001b[01;34m123\u001b[0m/  \u001b[01;34m134\u001b[0m/  \u001b[01;34m145\u001b[0m/  checksums\n",
            "\u001b[01;34m003\u001b[0m/  \u001b[01;34m014\u001b[0m/  \u001b[01;34m025\u001b[0m/  \u001b[01;34m036\u001b[0m/  \u001b[01;34m047\u001b[0m/  \u001b[01;34m058\u001b[0m/  \u001b[01;34m069\u001b[0m/  \u001b[01;34m080\u001b[0m/  \u001b[01;34m091\u001b[0m/  \u001b[01;34m102\u001b[0m/  \u001b[01;34m113\u001b[0m/  \u001b[01;34m124\u001b[0m/  \u001b[01;34m135\u001b[0m/  \u001b[01;34m146\u001b[0m/  README.txt\n",
            "\u001b[01;34m004\u001b[0m/  \u001b[01;34m015\u001b[0m/  \u001b[01;34m026\u001b[0m/  \u001b[01;34m037\u001b[0m/  \u001b[01;34m048\u001b[0m/  \u001b[01;34m059\u001b[0m/  \u001b[01;34m070\u001b[0m/  \u001b[01;34m081\u001b[0m/  \u001b[01;34m092\u001b[0m/  \u001b[01;34m103\u001b[0m/  \u001b[01;34m114\u001b[0m/  \u001b[01;34m125\u001b[0m/  \u001b[01;34m136\u001b[0m/  \u001b[01;34m147\u001b[0m/\n",
            "\u001b[01;34m005\u001b[0m/  \u001b[01;34m016\u001b[0m/  \u001b[01;34m027\u001b[0m/  \u001b[01;34m038\u001b[0m/  \u001b[01;34m049\u001b[0m/  \u001b[01;34m060\u001b[0m/  \u001b[01;34m071\u001b[0m/  \u001b[01;34m082\u001b[0m/  \u001b[01;34m093\u001b[0m/  \u001b[01;34m104\u001b[0m/  \u001b[01;34m115\u001b[0m/  \u001b[01;34m126\u001b[0m/  \u001b[01;34m137\u001b[0m/  \u001b[01;34m148\u001b[0m/\n",
            "\u001b[01;34m006\u001b[0m/  \u001b[01;34m017\u001b[0m/  \u001b[01;34m028\u001b[0m/  \u001b[01;34m039\u001b[0m/  \u001b[01;34m050\u001b[0m/  \u001b[01;34m061\u001b[0m/  \u001b[01;34m072\u001b[0m/  \u001b[01;34m083\u001b[0m/  \u001b[01;34m094\u001b[0m/  \u001b[01;34m105\u001b[0m/  \u001b[01;34m116\u001b[0m/  \u001b[01;34m127\u001b[0m/  \u001b[01;34m138\u001b[0m/  \u001b[01;34m149\u001b[0m/\n",
            "\u001b[01;34m007\u001b[0m/  \u001b[01;34m018\u001b[0m/  \u001b[01;34m029\u001b[0m/  \u001b[01;34m040\u001b[0m/  \u001b[01;34m051\u001b[0m/  \u001b[01;34m062\u001b[0m/  \u001b[01;34m073\u001b[0m/  \u001b[01;34m084\u001b[0m/  \u001b[01;34m095\u001b[0m/  \u001b[01;34m106\u001b[0m/  \u001b[01;34m117\u001b[0m/  \u001b[01;34m128\u001b[0m/  \u001b[01;34m139\u001b[0m/  \u001b[01;34m150\u001b[0m/\n",
            "\u001b[01;34m008\u001b[0m/  \u001b[01;34m019\u001b[0m/  \u001b[01;34m030\u001b[0m/  \u001b[01;34m041\u001b[0m/  \u001b[01;34m052\u001b[0m/  \u001b[01;34m063\u001b[0m/  \u001b[01;34m074\u001b[0m/  \u001b[01;34m085\u001b[0m/  \u001b[01;34m096\u001b[0m/  \u001b[01;34m107\u001b[0m/  \u001b[01;34m118\u001b[0m/  \u001b[01;34m129\u001b[0m/  \u001b[01;34m140\u001b[0m/  \u001b[01;34m151\u001b[0m/\n",
            "\u001b[01;34m009\u001b[0m/  \u001b[01;34m020\u001b[0m/  \u001b[01;34m031\u001b[0m/  \u001b[01;34m042\u001b[0m/  \u001b[01;34m053\u001b[0m/  \u001b[01;34m064\u001b[0m/  \u001b[01;34m075\u001b[0m/  \u001b[01;34m086\u001b[0m/  \u001b[01;34m097\u001b[0m/  \u001b[01;34m108\u001b[0m/  \u001b[01;34m119\u001b[0m/  \u001b[01;34m130\u001b[0m/  \u001b[01;34m141\u001b[0m/  \u001b[01;34m152\u001b[0m/\n",
            "\u001b[01;34m010\u001b[0m/  \u001b[01;34m021\u001b[0m/  \u001b[01;34m032\u001b[0m/  \u001b[01;34m043\u001b[0m/  \u001b[01;34m054\u001b[0m/  \u001b[01;34m065\u001b[0m/  \u001b[01;34m076\u001b[0m/  \u001b[01;34m087\u001b[0m/  \u001b[01;34m098\u001b[0m/  \u001b[01;34m109\u001b[0m/  \u001b[01;34m120\u001b[0m/  \u001b[01;34m131\u001b[0m/  \u001b[01;34m142\u001b[0m/  \u001b[01;34m153\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls fma_small/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtGR-YmGcoir",
        "outputId": "3c3b9665-c9e5-4aba-a08f-ec803efaf7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-directory content: ['002097.mp3', '002012.mp3', '002099.mp3', '002096.mp3']\n"
          ]
        }
      ],
      "source": [
        "some_sub_dir = os.path.join(audio_dir, '002')\n",
        "print(\"Sub-directory content:\", os.listdir(some_sub_dir)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMmRccvxhFLu",
        "outputId": "88f03d9f-52d7-47d5-c3fb-92f2198aa472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  341M  100  341M    0     0  18.4M      0  0:00:18  0:00:18 --:--:-- 20.6M\n",
            "Archive:  fma_metadata.zip\n",
            " bunzipping: fma_metadata/README.txt  \n",
            " bunzipping: fma_metadata/checksums  \n",
            " bunzipping: fma_metadata/not_found.pickle  \n",
            " bunzipping: fma_metadata/raw_genres.csv  \n",
            " bunzipping: fma_metadata/raw_albums.csv  \n",
            " bunzipping: fma_metadata/raw_artists.csv  \n",
            " bunzipping: fma_metadata/raw_tracks.csv  \n",
            " bunzipping: fma_metadata/tracks.csv  \n",
            " bunzipping: fma_metadata/genres.csv  \n",
            " bunzipping: fma_metadata/raw_echonest.csv  \n",
            " bunzipping: fma_metadata/echonest.csv  \n",
            " bunzipping: fma_metadata/features.csv  \n"
          ]
        }
      ],
      "source": [
        "# Download file and unzip\n",
        "!curl -O https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
        "!unzip fma_metadata.zip\n",
        "!rm fma_metadata.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wANuNiigk41-",
        "outputId": "26dafcb4-6a2c-46ec-94e8-0de0d4e864a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current Working Directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVw-yt1uk85l",
        "outputId": "0d959d8e-d8f6-4995-b823-763f4320a6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory Contents: ['.config', 'fma_small', 'fma_metadata', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "print(\"Directory Contents:\", os.listdir())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5QvE8pYlEfq",
        "outputId": "fe2d13dc-64c8-4006-94c8-408f0f062dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP file exists at /content/fma_metadata\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the zip file and the extraction directory\n",
        "zip_file_path = '/content/fma_metadata'\n",
        "extraction_directory = os.getcwd()  # or any directory where you want to extract files\n",
        "\n",
        "if os.path.exists(zip_file_path):\n",
        "    print(f\"ZIP file exists at {zip_file_path}\")\n",
        "else:\n",
        "    print(\"ZIP file does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9k6zXVqnN26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import multiprocessing\n",
        "import warnings\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import ast  # Make sure this line is added\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr6Y_4F7mfFX",
        "outputId": "55a2a76b-4326-4782-cd18-00e3c6241935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tracks.csv exists at /content/fma_metadata/tracks.csv\n"
          ]
        }
      ],
      "source": [
        "# Define the path where you expect the 'tracks.csv' file\n",
        "tracks_csv_path = '/content/fma_metadata/tracks.csv'\n",
        "\n",
        "# Check if tracks.csv exists at the specified path\n",
        "if os.path.exists(tracks_csv_path):\n",
        "    print(f\"tracks.csv exists at {tracks_csv_path}\")\n",
        "else:\n",
        "    print(\"tracks.csv does not exist at the expected location.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJOmDN0Vn5P3"
      },
      "outputs": [],
      "source": [
        "# Number of samples per 30s audio clip.\n",
        "# TODO: fix dataset to be constant.\n",
        "NB_AUDIO_SAMPLES = 1321967\n",
        "SAMPLING_RATE = 44100\n",
        "import numpy as np\n",
        "\n",
        "class Loader:\n",
        "    def load(self, filepath):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "class RawAudioLoader(Loader):\n",
        "    def __init__(self, sampling_rate=SAMPLING_RATE):\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.nb_samples = NB_AUDIO_SAMPLES\n",
        "\n",
        "    def load(self, filepath):\n",
        "        data = self._load(filepath)\n",
        "        # Pad the waveform if it's shorter than expected\n",
        "        if len(data) < self.nb_samples:\n",
        "            padding = np.zeros(self.nb_samples - len(data))\n",
        "            data = np.concatenate((data, padding))\n",
        "        # Trim the waveform if it's longer than expected\n",
        "        elif len(data) > self.nb_samples:\n",
        "            data = data[:self.nb_samples]\n",
        "        return data\n",
        "\n",
        "class LibrosaLoader(RawAudioLoader):\n",
        "    def _load(self, filepath):\n",
        "        import librosa\n",
        "        # Use 'None' for original sampling rate, or set a new rate\n",
        "        sr = self.sampling_rate if self.sampling_rate != SAMPLING_RATE else None\n",
        "        # Load with librosa\n",
        "        x, _ = librosa.load(filepath, sr=sr, res_type='kaiser_fast')\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE4LMAnwUyAX"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# FMA: A Dataset For Music Analysis\n",
        "# Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
        "\n",
        "# All features are extracted using [librosa](https://github.com/librosa/librosa).\n",
        "# Alternatives:\n",
        "# * [Essentia](http://essentia.upf.edu) (C++ with Python bindings)\n",
        "# * [MARSYAS](https://github.com/marsyas/marsyas) (C++ with Python bindings)\n",
        "# * [RP extract](http://www.ifs.tuwien.ac.at/mir/downloads.html) (Matlab, Java, Python)\n",
        "# * [jMIR jAudio](http://jmir.sourceforge.net) (Java)\n",
        "# * [MIRtoolbox](https://www.jyu.fi/hum/laitokset/musiikki/en/research/coe/materials/mirtoolbox) (Matlab)\n",
        "\n",
        "import os\n",
        "import multiprocessing\n",
        "import warnings\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "#utils\n",
        "def load(filepath):\n",
        "\n",
        "    filename = os.path.basename(filepath)\n",
        "\n",
        "    if 'features' in filename:\n",
        "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
        "\n",
        "    if 'echonest' in filename:\n",
        "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
        "\n",
        "    if 'genres' in filename:\n",
        "        return pd.read_csv(filepath, index_col=0)\n",
        "\n",
        "    if 'tracks' in filename:\n",
        "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
        "\n",
        "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
        "                   ('track', 'genres'), ('track', 'genres_all')]\n",
        "        for column in COLUMNS:\n",
        "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
        "\n",
        "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
        "                   ('album', 'date_created'), ('album', 'date_released'),\n",
        "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
        "                   ('artist', 'active_year_end')]\n",
        "        for column in COLUMNS:\n",
        "            tracks[column] = pd.to_datetime(tracks[column])\n",
        "\n",
        "        SUBSETS = ('small', 'medium', 'large')\n",
        "        try:\n",
        "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "                    'category', categories=SUBSETS, ordered=True)\n",
        "        except (ValueError, TypeError):\n",
        "            # the categories and ordered arguments were removed in pandas 0.25\n",
        "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "                     pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
        "\n",
        "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
        "                   ('album', 'type'), ('album', 'information'),\n",
        "                   ('artist', 'bio')]\n",
        "        for column in COLUMNS:\n",
        "            tracks[column] = tracks[column].astype('category')\n",
        "\n",
        "        return tracks\n",
        "\n",
        "def columns():\n",
        "    feature_sizes = dict(chroma_stft=12, chroma_cqt=12, chroma_cens=12,\n",
        "                         tonnetz=6, mfcc=20, rmse=1, zcr=1,\n",
        "                         spectral_centroid=1, spectral_bandwidth=1,\n",
        "                         spectral_contrast=7, spectral_rolloff=1)\n",
        "    moments = ('mean', 'std', 'skew', 'kurtosis', 'median', 'min', 'max')\n",
        "\n",
        "    columns = []\n",
        "    for name, size in feature_sizes.items():\n",
        "        for moment in moments:\n",
        "            it = ((name, moment, '{:02d}'.format(i+1)) for i in range(size))\n",
        "            columns.extend(it)\n",
        "\n",
        "    names = ('feature', 'statistics', 'number')\n",
        "    columns = pd.MultiIndex.from_tuples(columns, names=names)\n",
        "\n",
        "    # More efficient to slice if indexes are sorted.\n",
        "    return columns.sort_values()\n",
        "\n",
        "\n",
        "def compute_features(tid):\n",
        "\n",
        "    features = pd.Series(index=columns(), dtype=np.float32, name=tid)\n",
        "    loader = LibrosaLoader(sampling_rate=44100)  # Initialize your custom loader\n",
        "\n",
        "\n",
        "    def feature_stats(name, values):\n",
        "        features[(name, 'mean')] = np.mean(values, axis=1)\n",
        "        features[(name, 'std')] = np.std(values, axis=1)\n",
        "        features[(name, 'skew')] = stats.skew(values, axis=1)\n",
        "        features[(name, 'kurtosis')] = stats.kurtosis(values, axis=1)\n",
        "        features[(name, 'median')] = np.median(values, axis=1)\n",
        "        features[(name, 'min')] = np.min(values, axis=1)\n",
        "        features[(name, 'max')] = np.max(values, axis=1)\n",
        "\n",
        "\n",
        "    try:\n",
        "        filepath = get_audio_path(os.environ.get('AUDIO_DIR'), tid)\n",
        "        x = loader.load(filepath)  # Load audio data using the custom loader\n",
        "        assert len(x) == NB_AUDIO_SAMPLES, f\"Track {tid} length mismatch: {len(x)} samples, expected {NB_AUDIO_SAMPLES}\"\n",
        "\n",
        "        sr = loader.sampling_rate  # Ensure sampling rate consistency\n",
        "\n",
        "        f = librosa.feature.zero_crossing_rate(x, frame_length=2048, hop_length=512)\n",
        "        feature_stats('zcr', f)\n",
        "\n",
        "        cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12,\n",
        "                                 n_bins=7*12, tuning=None))\n",
        "        assert cqt.shape[0] == 7 * 12\n",
        "        assert np.ceil(len(x)/512) <= cqt.shape[1] <= np.ceil(len(x)/512)+1\n",
        "\n",
        "        f = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
        "        feature_stats('chroma_cqt', f)\n",
        "        f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
        "        feature_stats('chroma_cens', f)\n",
        "        f = librosa.feature.tonnetz(chroma=f)\n",
        "        feature_stats('tonnetz', f)\n",
        "\n",
        "        del cqt\n",
        "        stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
        "        assert stft.shape[0] == 1 + 2048 // 2\n",
        "        assert np.ceil(len(x)/512) <= stft.shape[1] <= np.ceil(len(x)/512)+1\n",
        "        del x\n",
        "\n",
        "        f = librosa.feature.chroma_stft(S=stft**2, n_chroma=12)\n",
        "        feature_stats('chroma_stft', f)\n",
        "\n",
        "        f = librosa.feature.rmse(S=stft)\n",
        "        feature_stats('rmse', f)\n",
        "\n",
        "        f = librosa.feature.spectral_centroid(S=stft)\n",
        "        feature_stats('spectral_centroid', f)\n",
        "        f = librosa.feature.spectral_bandwidth(S=stft)\n",
        "        feature_stats('spectral_bandwidth', f)\n",
        "        f = librosa.feature.spectral_contrast(S=stft, n_bands=6)\n",
        "        feature_stats('spectral_contrast', f)\n",
        "        f = librosa.feature.spectral_rolloff(S=stft)\n",
        "        feature_stats('spectral_rolloff', f)\n",
        "\n",
        "        mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
        "        del stft\n",
        "        f = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
        "        feature_stats('mfcc', f)\n",
        "\n",
        "    except Exception as e:\n",
        "        print('{}: {}'.format(tid, repr(e)))\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def main():\n",
        "    tracks = load('tracks.csv')\n",
        "    specific_tids = [2, 3, 5, 10, 20, 26, 30, 46]\n",
        "\n",
        "    features = pd.DataFrame(index=tracks.index(specefic_tids, name='track_id'),\n",
        "                            columns=columns(), dtype=np.float32)\n",
        "\n",
        "    # More than usable CPUs to be CPU bound, not I/O bound. Beware memory.\n",
        "    nb_workers = min(4, len(os.sched_getaffinity(0)))\n",
        "    # int(1.5 * len(os.sched_getaffinity(0)))\n",
        "\n",
        "    pool = multiprocessing.Pool(nb_workers)\n",
        "    it = pool.imap_unordered(compute_features, specific_tids)\n",
        "\n",
        "    for i, row in enumerate(tqdm(it, total=len(specific_tids))):\n",
        "        features.loc[row.name] = row\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            save(features, 10)\n",
        "\n",
        "    save(features, 10)\n",
        "    test(features, 10)\n",
        "\n",
        "\n",
        "def save(features, ndigits):\n",
        "\n",
        "    # Should be done already, just to be sure.\n",
        "    features.sort_index(axis=0, inplace=True)\n",
        "    features.sort_index(axis=1, inplace=True)\n",
        "\n",
        "    features.to_csv('features.csv', float_format='%.{}e'.format(ndigits))\n",
        "\n",
        "\n",
        "def test(features, ndigits):\n",
        "\n",
        "    indices = features[features.isnull().any(axis=1)].index\n",
        "    if len(indices) > 0:\n",
        "        print('Failed tracks: {}'.format(', '.join(str(i) for i in indices)))\n",
        "\n",
        "    tmp = load('features.csv')\n",
        "    np.testing.assert_allclose(tmp.values, features.values, rtol=10**-ndigits)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvRllyg9mlOu"
      },
      "outputs": [],
      "source": [
        "# Assuming tracks.csv was found in the previous step\n",
        "tracks = load(tracks_csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Wjy0H0naHD",
        "outputId": "37e97b96-2bcb-4c69-cc68-d137888cb9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            album                                                              \\\n",
            "         comments        date_created date_released engineer favorites     id   \n",
            "track_id                                                                        \n",
            "2               0 2008-11-26 01:44:45    2009-01-05      NaN         4      1   \n",
            "3               0 2008-11-26 01:44:45    2009-01-05      NaN         4      1   \n",
            "5               0 2008-11-26 01:44:45    2009-01-05      NaN         4      1   \n",
            "10              0 2008-11-26 01:45:08    2008-02-06      NaN         4      6   \n",
            "20              0 2008-11-26 01:45:05    2009-01-06      NaN         2      4   \n",
            "...           ...                 ...           ...      ...       ...    ...   \n",
            "155316          0 2017-03-30 15:20:35    2017-02-17      NaN         0  22940   \n",
            "155317          0 2017-03-30 15:20:35    2017-02-17      NaN         0  22940   \n",
            "155318          0 2017-03-30 15:20:35    2017-02-17      NaN         0  22940   \n",
            "155319          0 2017-03-30 15:20:35    2017-02-17      NaN         0  22940   \n",
            "155320          0 2017-03-26 16:22:18    2017-03-26      NaN         1  22906   \n",
            "\n",
            "                                                                     \\\n",
            "                                                information listens   \n",
            "track_id                                                              \n",
            "2                                                   <p></p>    6073   \n",
            "3                                                   <p></p>    6073   \n",
            "5                                                   <p></p>    6073   \n",
            "10                                                      NaN   47632   \n",
            "20                <p> \"spiritual songs\" from Nicky Cook</p>    2710   \n",
            "...                                                     ...     ...   \n",
            "155316    <p>A live performance at Monty Hall on Feb 17,...    1506   \n",
            "155317    <p>A live performance at Monty Hall on Feb 17,...    1506   \n",
            "155318    <p>A live performance at Monty Hall on Feb 17,...    1506   \n",
            "155319    <p>A live performance at Monty Hall on Feb 17,...    1506   \n",
            "155320                                                  NaN    7481   \n",
            "\n",
            "                                                                          ...  \\\n",
            "             producer                                               tags  ...   \n",
            "track_id                                                                  ...   \n",
            "2                 NaN                                                 []  ...   \n",
            "3                 NaN                                                 []  ...   \n",
            "5                 NaN                                                 []  ...   \n",
            "10                NaN                                                 []  ...   \n",
            "20                NaN                                                 []  ...   \n",
            "...               ...                                                ...  ...   \n",
            "155316    Monty Hall                                                  []  ...   \n",
            "155317    Monty Hall                                                  []  ...   \n",
            "155318    Monty Hall                                                  []  ...   \n",
            "155319    Monty Hall                                                  []  ...   \n",
            "155320            NaN  [ballad, epic, rockabilly, curse, hex, hard ro...  ...   \n",
            "\n",
            "               track                         \\\n",
            "         information interest language_code   \n",
            "track_id                                      \n",
            "2                NaN     4656            en   \n",
            "3                NaN     1470            en   \n",
            "5                NaN     1933            en   \n",
            "10               NaN    54881            en   \n",
            "20               NaN      978            en   \n",
            "...              ...      ...           ...   \n",
            "155316           NaN      122           NaN   \n",
            "155317           NaN      194           NaN   \n",
            "155318           NaN      214           NaN   \n",
            "155319           NaN      336           NaN   \n",
            "155320           NaN      972           NaN   \n",
            "\n",
            "                                                                              \\\n",
            "                                                    license listens lyricist   \n",
            "track_id                                                                       \n",
            "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
            "3         Attribution-NonCommercial-ShareAlike 3.0 Inter...     514      NaN   \n",
            "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
            "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
            "20        Attribution-NonCommercial-NoDerivatives (aka M...     361      NaN   \n",
            "...                                                     ...     ...      ...   \n",
            "155316    Creative Commons Attribution-NonCommercial-NoD...     102      NaN   \n",
            "155317    Creative Commons Attribution-NonCommercial-NoD...     165      NaN   \n",
            "155318    Creative Commons Attribution-NonCommercial-NoD...     168      NaN   \n",
            "155319    Creative Commons Attribution-NonCommercial-NoD...     294      NaN   \n",
            "155320                            Attribution-NonCommercial     705      NaN   \n",
            "\n",
            "                                                                              \\\n",
            "         number publisher                                               tags   \n",
            "track_id                                                                       \n",
            "2             3       NaN                                                 []   \n",
            "3             4       NaN                                                 []   \n",
            "5             6       NaN                                                 []   \n",
            "10            1       NaN                                                 []   \n",
            "20            3       NaN                                                 []   \n",
            "...         ...       ...                                                ...   \n",
            "155316        3       NaN                                                 []   \n",
            "155317        4       NaN                                                 []   \n",
            "155318        6       NaN                                                 []   \n",
            "155319        5       NaN                                                 []   \n",
            "155320        7       NaN  [ballad, epic, rockabilly, curse, hex, hard ro...   \n",
            "\n",
            "                                                     \n",
            "                                              title  \n",
            "track_id                                             \n",
            "2                                              Food  \n",
            "3                                      Electric Ave  \n",
            "5                                        This World  \n",
            "10                                          Freeway  \n",
            "20                                  Spiritual Level  \n",
            "...                                             ...  \n",
            "155316                                    The Auger  \n",
            "155317                              Let's Skin Ruby  \n",
            "155318           My House Smells Like Kim Deal/Pulp  \n",
            "155319                      The Man With Two Mouths  \n",
            "155320    Another Trick Up My Sleeve (Instrumental)  \n",
            "\n",
            "[106574 rows x 52 columns]\n"
          ]
        }
      ],
      "source": [
        "# Assuming tracks.csv was found and loaded successfully\n",
        "print(tracks)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if the file exists at the specified path\n",
        "if os.path.exists(tracks_csv_path):\n",
        "    print(\"File found, proceeding with loading.\")\n",
        "    tracks = load(tracks_csv_path)\n",
        "else:\n",
        "    print(f\"File not found at {tracks_csv_path}. Please check the file path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY-uSS25czNW",
        "outputId": "4301f396-cce8-4ad2-f5cf-5142b7ec3df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found, proceeding with loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After confirming that tracks.csv is loaded successfully\n",
        "\n",
        "# Explore the first few entries in the dataframe\n",
        "print(tracks.head())\n",
        "\n",
        "# Check for missing values in tracks\n",
        "print(tracks.isnull().sum())\n",
        "\n",
        "# Basic statistical analysis of numerical columns\n",
        "print(tracks.describe())\n",
        "\n",
        "# Load features.csv\n",
        "features_csv_path = '/content/fma_metadata/features.csv'  # update with your actual path\n",
        "if os.path.exists(features_csv_path):\n",
        "    print(\"Loading features.csv\")\n",
        "    features = load(features_csv_path)\n",
        "    print(features.info())\n",
        "\n",
        "    # Handle missing values\n",
        "    # If missing values are not numerous and are not critical, you can drop them\n",
        "    features.dropna(inplace=True)\n",
        "else:\n",
        "    print(f\"File not found at {features_csv_path}. Please check the file path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3qct3r8YMm0",
        "outputId": "3690ab6c-7a52-43b7-b0a9-6d7044418acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            album                                                          \\\n",
            "         comments        date_created date_released engineer favorites id   \n",
            "track_id                                                                    \n",
            "2               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
            "3               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
            "5               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
            "10              0 2008-11-26 01:45:08    2008-02-06      NaN         4  6   \n",
            "20              0 2008-11-26 01:45:05    2009-01-06      NaN         2  4   \n",
            "\n",
            "                                                                           \\\n",
            "                                        information listens producer tags   \n",
            "track_id                                                                    \n",
            "2                                           <p></p>    6073      NaN   []   \n",
            "3                                           <p></p>    6073      NaN   []   \n",
            "5                                           <p></p>    6073      NaN   []   \n",
            "10                                              NaN   47632      NaN   []   \n",
            "20        <p> \"spiritual songs\" from Nicky Cook</p>    2710      NaN   []   \n",
            "\n",
            "          ...       track                         \\\n",
            "          ... information interest language_code   \n",
            "track_id  ...                                      \n",
            "2         ...         NaN     4656            en   \n",
            "3         ...         NaN     1470            en   \n",
            "5         ...         NaN     1933            en   \n",
            "10        ...         NaN    54881            en   \n",
            "20        ...         NaN      978            en   \n",
            "\n",
            "                                                                              \\\n",
            "                                                    license listens lyricist   \n",
            "track_id                                                                       \n",
            "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
            "3         Attribution-NonCommercial-ShareAlike 3.0 Inter...     514      NaN   \n",
            "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
            "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
            "20        Attribution-NonCommercial-NoDerivatives (aka M...     361      NaN   \n",
            "\n",
            "                                                 \n",
            "         number publisher tags            title  \n",
            "track_id                                         \n",
            "2             3       NaN   []             Food  \n",
            "3             4       NaN   []     Electric Ave  \n",
            "5             6       NaN   []       This World  \n",
            "10            1       NaN   []          Freeway  \n",
            "20            3       NaN   []  Spiritual Level  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "album   comments                  0\n",
            "        date_created           3529\n",
            "        date_released         36280\n",
            "        engineer              91279\n",
            "        favorites                 0\n",
            "        id                        0\n",
            "        information           23425\n",
            "        listens                   0\n",
            "        producer              88514\n",
            "        tags                      0\n",
            "        title                  1025\n",
            "        tracks                    0\n",
            "        type                   6508\n",
            "artist  active_year_begin     83863\n",
            "        active_year_end      101199\n",
            "        associated_labels     92303\n",
            "        bio                   35418\n",
            "        comments                  0\n",
            "        date_created            856\n",
            "        favorites                 0\n",
            "        id                        0\n",
            "        latitude              62030\n",
            "        location              36364\n",
            "        longitude             62030\n",
            "        members               59725\n",
            "        name                      0\n",
            "        related_projects      93422\n",
            "        tags                      0\n",
            "        website               27318\n",
            "        wikipedia_page       100993\n",
            "set     split                     0\n",
            "        subset                    0\n",
            "track   bit_rate                  0\n",
            "        comments                  0\n",
            "        composer             102904\n",
            "        date_created              0\n",
            "        date_recorded        100415\n",
            "        duration                  0\n",
            "        favorites                 0\n",
            "        genre_top             56976\n",
            "        genres                    0\n",
            "        genres_all                0\n",
            "        information          104225\n",
            "        interest                  0\n",
            "        language_code         91550\n",
            "        license                  87\n",
            "        listens                   0\n",
            "        lyricist             106263\n",
            "        number                    0\n",
            "        publisher            105311\n",
            "        tags                      0\n",
            "        title                     1\n",
            "dtype: int64\n",
            "               album                                 \\\n",
            "            comments                   date_created   \n",
            "count  106574.000000                         103045   \n",
            "mean        0.394946  2013-02-04 03:19:28.257392640   \n",
            "min        -1.000000            2008-11-26 01:44:45   \n",
            "25%         0.000000            2010-11-28 23:33:53   \n",
            "50%         0.000000            2013-02-07 16:56:28   \n",
            "75%         0.000000            2015-05-11 15:12:19   \n",
            "max        53.000000            2017-03-30 15:20:35   \n",
            "std         2.268915                            NaN   \n",
            "\n",
            "                                                                    \\\n",
            "                       date_released      favorites             id   \n",
            "count                          70294  106574.000000  106574.000000   \n",
            "mean   2011-04-05 04:41:03.572993536       1.286927   12826.933914   \n",
            "min              1902-01-01 00:00:00      -1.000000      -1.000000   \n",
            "25%              2009-04-15 00:00:00       0.000000    7793.000000   \n",
            "50%              2011-12-31 00:00:00       0.000000   13374.000000   \n",
            "75%              2014-04-08 00:00:00       1.000000   18203.000000   \n",
            "max              2021-03-01 00:00:00      61.000000   22940.000000   \n",
            "std                              NaN       3.133035    6290.261805   \n",
            "\n",
            "                                                           artist  \\\n",
            "            listens         tracks              active_year_begin   \n",
            "count  1.065740e+05  106574.000000                          22711   \n",
            "mean   3.212031e+04      19.721452  2001-11-10 10:44:30.952401792   \n",
            "min   -1.000000e+00      -1.000000            1903-01-01 00:00:00   \n",
            "25%    3.361000e+03       7.000000            1998-01-01 00:00:00   \n",
            "50%    8.982000e+03      11.000000            2004-01-01 00:00:00   \n",
            "75%    2.363500e+04      17.000000            2008-01-01 00:00:00   \n",
            "max    3.564243e+06     652.000000            2016-01-01 00:00:00   \n",
            "std    1.478532e+05      39.943673                            NaN   \n",
            "\n",
            "                                                     ...                \\\n",
            "                     active_year_end       comments  ...     longitude   \n",
            "count                           5375  106574.000000  ...  44544.000000   \n",
            "mean   2009-10-14 19:25:07.646511872       1.894702  ...    -38.668642   \n",
            "min              1903-01-01 00:00:00      -1.000000  ...   -157.526855   \n",
            "25%              2006-01-01 00:00:00       0.000000  ...    -79.997459   \n",
            "50%              2011-01-01 00:00:00       0.000000  ...    -73.554431   \n",
            "75%              2015-01-01 00:00:00       1.000000  ...      4.351710   \n",
            "max              2086-01-01 00:00:00      79.000000  ...    175.277000   \n",
            "std                              NaN       6.297679  ...     65.237220   \n",
            "\n",
            "               track                                                \\\n",
            "            bit_rate       comments                   date_created   \n",
            "count  106574.000000  106574.000000                         106574   \n",
            "mean   263274.695048       0.031621  2013-02-16 11:35:26.971409664   \n",
            "min        -1.000000       0.000000            2008-11-25 17:49:06   \n",
            "25%    192000.000000       0.000000  2010-12-15 18:25:34.750000128   \n",
            "50%    299914.000000       0.000000     2013-02-23 01:33:41.500000   \n",
            "75%    320000.000000       0.000000            2015-05-12 11:36:21   \n",
            "max    448000.000000      37.000000            2017-03-30 15:23:39   \n",
            "std     67623.443584       0.321993                            NaN   \n",
            "\n",
            "                                                                    \\\n",
            "                       date_recorded       duration      favorites   \n",
            "count                           6159  106574.000000  106574.000000   \n",
            "mean   2003-06-05 05:03:28.670238848     277.849100       3.182521   \n",
            "min              1896-01-01 00:00:00       0.000000       0.000000   \n",
            "25%              2005-03-09 00:00:00     149.000000       0.000000   \n",
            "50%              2008-06-26 00:00:00     216.000000       1.000000   \n",
            "75%              2009-02-06 12:00:00     305.000000       3.000000   \n",
            "max              2017-03-14 00:00:00   18350.000000    1482.000000   \n",
            "std                              NaN     305.518553      13.513820   \n",
            "\n",
            "                                                   \n",
            "           interest        listens         number  \n",
            "count  1.065740e+05  106574.000000  106574.000000  \n",
            "mean   3.541310e+03    2329.353548       8.260945  \n",
            "min    2.000000e+00       0.000000       0.000000  \n",
            "25%    5.990000e+02     292.000000       2.000000  \n",
            "50%    1.314000e+03     764.000000       5.000000  \n",
            "75%    3.059000e+03    2018.000000       9.000000  \n",
            "max    3.293557e+06  543252.000000     255.000000  \n",
            "std    1.901743e+04    8028.070647      15.243271  \n",
            "\n",
            "[8 rows x 24 columns]\n",
            "Loading features.csv\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 106574 entries, 2 to 155320\n",
            "Columns: 518 entries, ('chroma_cens', 'kurtosis', '01') to ('zcr', 'std', '01')\n",
            "dtypes: float64(518)\n",
            "memory usage: 422.0 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the tracks DataFrame with the correct hierarchical column indexing\n",
        "tracks = pd.read_csv(tracks_csv_path, index_col=0, header=[0, 1], low_memory=False)\n",
        "\n",
        "# Access the 'genre_top' field directly\n",
        "# The name 'genre_top' will be used assuming it is under the 'track' level of the DataFrame\n",
        "genre_top_series = tracks[('track', 'genre_top')]\n",
        "\n",
        "# Now we need to flatten the multi-level index for features\n",
        "# Convert the multi-level column names into a single level by concatenating the levels\n",
        "features.columns = ['_'.join(col).strip() for col in features.columns.values]\n",
        "\n",
        "# Filter out tracks without genre information\n",
        "genre_top_series = genre_top_series.dropna()\n",
        "\n",
        "# Align the indices of the tracks and features DataFrame, we only keep rows that are present in both\n",
        "common_indices = features.index.intersection(genre_top_series.index)\n",
        "features_filtered = features.loc[common_indices]\n",
        "genre_top_filtered = genre_top_series.loc[common_indices]\n",
        "\n",
        "# Prepare the features and labels for machine learning\n",
        "X = features_filtered\n",
        "y = genre_top_filtered\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature values\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
        "\n",
        "# Train the classifier\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy of the KNN classifier: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dw8zaBYbTBV",
        "outputId": "ccbfcbd3-4b1c-4f9d-b898-7e6ceca50503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the KNN classifier: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtbZJ59-s3Gc",
        "outputId": "7a8ca176-5619-413b-a9b5-c00743f5548d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgxYz53ytxIz",
        "outputId": "4d311266-4b96-4884-b92d-d31e80806cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.py  \u001b[0m\u001b[01;34mfma_metadata\u001b[0m/  \u001b[01;34mfma_small\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/fma_small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qpWQvQZx2Yv",
        "outputId": "b7a54c8f-a4b2-4f34-a64c-567d11820125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m000\u001b[0m/  \u001b[01;34m011\u001b[0m/  \u001b[01;34m022\u001b[0m/  \u001b[01;34m033\u001b[0m/  \u001b[01;34m044\u001b[0m/  \u001b[01;34m055\u001b[0m/  \u001b[01;34m066\u001b[0m/  \u001b[01;34m077\u001b[0m/  \u001b[01;34m088\u001b[0m/  \u001b[01;34m099\u001b[0m/  \u001b[01;34m110\u001b[0m/  \u001b[01;34m121\u001b[0m/  \u001b[01;34m132\u001b[0m/  \u001b[01;34m143\u001b[0m/  \u001b[01;34m154\u001b[0m/\n",
            "\u001b[01;34m001\u001b[0m/  \u001b[01;34m012\u001b[0m/  \u001b[01;34m023\u001b[0m/  \u001b[01;34m034\u001b[0m/  \u001b[01;34m045\u001b[0m/  \u001b[01;34m056\u001b[0m/  \u001b[01;34m067\u001b[0m/  \u001b[01;34m078\u001b[0m/  \u001b[01;34m089\u001b[0m/  \u001b[01;34m100\u001b[0m/  \u001b[01;34m111\u001b[0m/  \u001b[01;34m122\u001b[0m/  \u001b[01;34m133\u001b[0m/  \u001b[01;34m144\u001b[0m/  \u001b[01;34m155\u001b[0m/\n",
            "\u001b[01;34m002\u001b[0m/  \u001b[01;34m013\u001b[0m/  \u001b[01;34m024\u001b[0m/  \u001b[01;34m035\u001b[0m/  \u001b[01;34m046\u001b[0m/  \u001b[01;34m057\u001b[0m/  \u001b[01;34m068\u001b[0m/  \u001b[01;34m079\u001b[0m/  \u001b[01;34m090\u001b[0m/  \u001b[01;34m101\u001b[0m/  \u001b[01;34m112\u001b[0m/  \u001b[01;34m123\u001b[0m/  \u001b[01;34m134\u001b[0m/  \u001b[01;34m145\u001b[0m/  checksums\n",
            "\u001b[01;34m003\u001b[0m/  \u001b[01;34m014\u001b[0m/  \u001b[01;34m025\u001b[0m/  \u001b[01;34m036\u001b[0m/  \u001b[01;34m047\u001b[0m/  \u001b[01;34m058\u001b[0m/  \u001b[01;34m069\u001b[0m/  \u001b[01;34m080\u001b[0m/  \u001b[01;34m091\u001b[0m/  \u001b[01;34m102\u001b[0m/  \u001b[01;34m113\u001b[0m/  \u001b[01;34m124\u001b[0m/  \u001b[01;34m135\u001b[0m/  \u001b[01;34m146\u001b[0m/  README.txt\n",
            "\u001b[01;34m004\u001b[0m/  \u001b[01;34m015\u001b[0m/  \u001b[01;34m026\u001b[0m/  \u001b[01;34m037\u001b[0m/  \u001b[01;34m048\u001b[0m/  \u001b[01;34m059\u001b[0m/  \u001b[01;34m070\u001b[0m/  \u001b[01;34m081\u001b[0m/  \u001b[01;34m092\u001b[0m/  \u001b[01;34m103\u001b[0m/  \u001b[01;34m114\u001b[0m/  \u001b[01;34m125\u001b[0m/  \u001b[01;34m136\u001b[0m/  \u001b[01;34m147\u001b[0m/\n",
            "\u001b[01;34m005\u001b[0m/  \u001b[01;34m016\u001b[0m/  \u001b[01;34m027\u001b[0m/  \u001b[01;34m038\u001b[0m/  \u001b[01;34m049\u001b[0m/  \u001b[01;34m060\u001b[0m/  \u001b[01;34m071\u001b[0m/  \u001b[01;34m082\u001b[0m/  \u001b[01;34m093\u001b[0m/  \u001b[01;34m104\u001b[0m/  \u001b[01;34m115\u001b[0m/  \u001b[01;34m126\u001b[0m/  \u001b[01;34m137\u001b[0m/  \u001b[01;34m148\u001b[0m/\n",
            "\u001b[01;34m006\u001b[0m/  \u001b[01;34m017\u001b[0m/  \u001b[01;34m028\u001b[0m/  \u001b[01;34m039\u001b[0m/  \u001b[01;34m050\u001b[0m/  \u001b[01;34m061\u001b[0m/  \u001b[01;34m072\u001b[0m/  \u001b[01;34m083\u001b[0m/  \u001b[01;34m094\u001b[0m/  \u001b[01;34m105\u001b[0m/  \u001b[01;34m116\u001b[0m/  \u001b[01;34m127\u001b[0m/  \u001b[01;34m138\u001b[0m/  \u001b[01;34m149\u001b[0m/\n",
            "\u001b[01;34m007\u001b[0m/  \u001b[01;34m018\u001b[0m/  \u001b[01;34m029\u001b[0m/  \u001b[01;34m040\u001b[0m/  \u001b[01;34m051\u001b[0m/  \u001b[01;34m062\u001b[0m/  \u001b[01;34m073\u001b[0m/  \u001b[01;34m084\u001b[0m/  \u001b[01;34m095\u001b[0m/  \u001b[01;34m106\u001b[0m/  \u001b[01;34m117\u001b[0m/  \u001b[01;34m128\u001b[0m/  \u001b[01;34m139\u001b[0m/  \u001b[01;34m150\u001b[0m/\n",
            "\u001b[01;34m008\u001b[0m/  \u001b[01;34m019\u001b[0m/  \u001b[01;34m030\u001b[0m/  \u001b[01;34m041\u001b[0m/  \u001b[01;34m052\u001b[0m/  \u001b[01;34m063\u001b[0m/  \u001b[01;34m074\u001b[0m/  \u001b[01;34m085\u001b[0m/  \u001b[01;34m096\u001b[0m/  \u001b[01;34m107\u001b[0m/  \u001b[01;34m118\u001b[0m/  \u001b[01;34m129\u001b[0m/  \u001b[01;34m140\u001b[0m/  \u001b[01;34m151\u001b[0m/\n",
            "\u001b[01;34m009\u001b[0m/  \u001b[01;34m020\u001b[0m/  \u001b[01;34m031\u001b[0m/  \u001b[01;34m042\u001b[0m/  \u001b[01;34m053\u001b[0m/  \u001b[01;34m064\u001b[0m/  \u001b[01;34m075\u001b[0m/  \u001b[01;34m086\u001b[0m/  \u001b[01;34m097\u001b[0m/  \u001b[01;34m108\u001b[0m/  \u001b[01;34m119\u001b[0m/  \u001b[01;34m130\u001b[0m/  \u001b[01;34m141\u001b[0m/  \u001b[01;34m152\u001b[0m/\n",
            "\u001b[01;34m010\u001b[0m/  \u001b[01;34m021\u001b[0m/  \u001b[01;34m032\u001b[0m/  \u001b[01;34m043\u001b[0m/  \u001b[01;34m054\u001b[0m/  \u001b[01;34m065\u001b[0m/  \u001b[01;34m076\u001b[0m/  \u001b[01;34m087\u001b[0m/  \u001b[01;34m098\u001b[0m/  \u001b[01;34m109\u001b[0m/  \u001b[01;34m120\u001b[0m/  \u001b[01;34m131\u001b[0m/  \u001b[01;34m142\u001b[0m/  \u001b[01;34m153\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/fma_small/001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGcQOL-ozXuc",
        "outputId": "e40f6505-8bdf-4295-d840-4c18e24a9ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "001039.mp3  001087.mp3  001270.mp3  001510.mp3  001673.mp3  001687.mp3  001720.mp3  001924.mp3\n",
            "001040.mp3  001102.mp3  001276.mp3  001544.mp3  001680.mp3  001688.mp3  001732.mp3  001925.mp3\n",
            "001066.mp3  001193.mp3  001277.mp3  001642.mp3  001681.mp3  001689.mp3  001733.mp3  001929.mp3\n",
            "001069.mp3  001195.mp3  001278.mp3  001644.mp3  001682.mp3  001701.mp3  001735.mp3  001930.mp3\n",
            "001073.mp3  001196.mp3  001417.mp3  001649.mp3  001683.mp3  001702.mp3  001736.mp3\n",
            "001075.mp3  001197.mp3  001427.mp3  001661.mp3  001684.mp3  001703.mp3  001883.mp3\n",
            "001082.mp3  001249.mp3  001443.mp3  001663.mp3  001685.mp3  001704.mp3  001891.mp3\n",
            "001083.mp3  001259.mp3  001482.mp3  001666.mp3  001686.mp3  001706.mp3  001893.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['AUDIO_DIR'] = '/content/fma_small'\n"
      ],
      "metadata": {
        "id": "KNwH7k-nbrGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqy1KVm8x9IE",
        "outputId": "7270c497-2b05-4d3b-c7e9-d47812439f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/features.py\n"
      ],
      "metadata": {
        "id": "TN3P_OtX17-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D_QTUkZMGuNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8mWCL7wpGuuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the Model**"
      ],
      "metadata": {
        "id": "sp0mfqsmNBtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the extracted features\n",
        "features_path = '/content/features.csv'\n",
        "features = pd.read_csv(features_path, index_col=0, header=[0, 1, 2])\n",
        "features.columns = ['_'.join(col).strip() for col in features.columns.values]\n",
        "\n",
        "# Load the tracks metadata which includes genres\n",
        "tracks_path = '/content/fma_metadata/tracks.csv'\n",
        "tracks = pd.read_csv(tracks_path, index_col=0, header=[0, 1])\n",
        "tracks.columns = ['_'.join(col).strip() for col in tracks.columns.values]\n",
        "\n",
        "# Extract genres as labels\n",
        "y = tracks['track_genre_top']\n",
        "\n",
        "# Align Data\n",
        "common_indices = features.index.intersection(y.index)\n",
        "features_filtered = features.loc[common_indices]\n",
        "y_filtered = y.loc[common_indices]\n",
        "\n",
        "# Drop columns where all values are NaN and replace any inf/-inf with NaN\n",
        "features_filtered.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "features_filtered.dropna(axis=1, how='all', inplace=True)\n",
        "features_filtered.fillna(0, inplace=True)\n",
        "\n",
        "# Handle missing labels if any\n",
        "y_filtered.fillna('Unknown', inplace=True)  # Assuming 'Unknown' is an acceptable category for your task\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_filtered, y_filtered, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check if any NaN values remain\n",
        "if X_train.isna().any().any() or X_test.isna().any().any():\n",
        "    print(\"NaN values still exist in the dataset!\")\n",
        "else:\n",
        "    print(\"No NaN values present. Proceeding with scaling.\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy of the KNN classifier on the test set: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiKNFmptI5zn",
        "outputId": "645032ee-66a6-4f1f-f5cb-195411fd2408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaN values present. Proceeding with scaling.\n",
            "Accuracy of the KNN classifier on the test set: 0.53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "              Blues       0.00      0.00      0.00        16\n",
            "          Classical       0.00      0.00      0.00       254\n",
            "            Country       0.00      0.00      0.00        44\n",
            "     Easy Listening       0.00      0.00      0.00         3\n",
            "         Electronic       0.00      0.00      0.00      1900\n",
            "       Experimental       0.67      0.00      0.01      2140\n",
            "               Folk       0.58      0.02      0.05       563\n",
            "            Hip-Hop       0.56      0.03      0.05       746\n",
            "       Instrumental       0.00      0.00      0.00       423\n",
            "      International       0.30      0.05      0.09       267\n",
            "               Jazz       0.00      0.00      0.00       109\n",
            "Old-Time / Historic       0.00      0.00      0.00       122\n",
            "                Pop       0.17      0.00      0.00       444\n",
            "               Rock       0.45      0.00      0.01      2886\n",
            "           Soul-RnB       0.00      0.00      0.00        45\n",
            "             Spoken       0.00      0.00      0.00        83\n",
            "            Unknown       0.53      1.00      0.70     11270\n",
            "\n",
            "           accuracy                           0.53     21315\n",
            "          macro avg       0.19      0.07      0.05     21315\n",
            "       weighted avg       0.45      0.53      0.37     21315\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}